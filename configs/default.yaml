# Techne Configuration Example
# This file demonstrates all available configuration options

model:
  name_or_path: "Qwen/Qwen2.5-7B-Instruct"
  torch_dtype: "bfloat16"
  attn_implementation: "flash_attention_2"
  trust_remote_code: true
  lora:
    enabled: true
    r: 64
    alpha: 128
    dropout: 0.05
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj
    bias: "none"
    task_type: "CAUSAL_LM"

# Customizable tags for tool calling
tags:
  tool_start: "<code>"
  tool_end: "</code>"
  response_start: "<interpreter>"
  response_end: "</interpreter>"

# Tool configuration
tools:
  sandbox_url: "http://127.0.0.1:5555"  # Microsandbox server URL
  sandbox_timeout: 30.0
  max_retries: 3
  concurrent_limit: 10

# Rollout configuration
rollout:
  backend: "vllm"  # or "sglang"
  max_turns: 10
  max_new_tokens: 4096
  temperature: 0.7
  top_p: 0.95
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.9

# Training configuration
training:
  algorithm: "grpo"  # ppo, grpo, or gspo
  learning_rate: 1.0e-6
  batch_size: 4
  gradient_accumulation_steps: 4
  max_steps: 1000
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  kl_coef: 0.0
  gamma: 1.0
  num_rollouts_per_prompt: 4
  # deepspeed_config: "./configs/ds_config.json"

# General settings
output_dir: "./output"
seed: 42
logging_steps: 10
save_steps: 100
