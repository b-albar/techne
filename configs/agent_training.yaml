# techne/configs/agent_training.yaml
model:
  name_or_path: "meta-llama/Llama-3-8B-Instruct"
  dtype: "bfloat16"
  lora:
    enabled: true
    r: 64
    alpha: 128
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

training:
  algorithm: "dft" # options: ppo, grpo, sft, dft
  learning_rate: 1.0e-6
  batch_size: 4
  gradient_accumulation_steps: 4
  max_steps: 1000
  max_seq_length: 4096
  report_to: "wandb"

output_dir: "./output/agent_v1"
seed: 42
logging_steps: 10
save_steps: 100
