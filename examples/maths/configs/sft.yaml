# SFT Training Configuration for Math Tool-Use

model:
  name_or_path: "Qwen/Qwen3-0.6B"
  dtype: "bfloat16"
  attn_implementation: "sdpa"
  trust_remote_code: true
  compile: true
  lora:
    enabled: true
    r: 64
    alpha: 128
    dropout: 0.05
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

training:
  algorithm: "sft"
  learning_rate: 2e-5
  batch_size: 2
  gradient_accumulation_steps: 32
  max_seq_length: 2048
  num_train_epochs: 6
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0

output_dir: "./output/sft"
seed: 42
logging_steps: 10
save_steps: 100
