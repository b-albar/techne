model:
  name_or_path: "Qwen/Qwen2.5-0.5B-Instruct"
  dtype: "bfloat16"
  attn_implementation: "eager"

training:
  algorithm: "distill"
  teacher_model: "Qwen/Qwen2.5-0.5B-Instruct" # Using same model as teacher for testing
  learning_rate: 1.0e-6
  batch_size: 4
  max_steps: 100
  num_inference_workers: 1
  num_training_workers: 1
  distributed_backend: "none"
  max_seq_length: 1024
  num_generations: 2
  kl_coef: 0.1
  clip_eps: 0.2

rollout:
  temperature: 0.7
  response_length: 512

output_dir: "outputs/distill_run"
logging_steps: 10
save_steps: 50
