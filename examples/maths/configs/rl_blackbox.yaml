# RL Training Configuration for Math Tool-Use (Black-Box with External Agent)

model:
  name_or_path: "./output/sft/checkpoint-final"  # For training, not rollout
  torch_dtype: "bfloat16"
  attn_implementation: "flash_attention_2"
  trust_remote_code: true
  lora:
    enabled: true
    r: 64
    alpha: 128
    dropout: 0.05
    target_modules:
      - q_proj
      - k_proj
      - v_proj
      - o_proj
      - gate_proj
      - up_proj
      - down_proj

tags:
  tool_start: "<code>"
  tool_end: "</code>"
  response_start: "<interpreter>"
  response_end: "</interpreter>"

tools:
  sandbox_url: null
  sandbox_timeout: 30.0
  max_retries: 3
  concurrent_limit: 10

# Note: rollout config not used for black-box
# External agent handles its own generation

training:
  algorithm: "grpo"
  learning_rate: 1e-6
  batch_size: 4
  gradient_accumulation_steps: 4
  max_steps: 150
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0

  # RL-specific
  kl_coef: 0.0
  gamma: 1.0
  num_rollouts_per_prompt: 4

output_dir: "./output/rl_blackbox"
seed: 42
logging_steps: 10
save_steps: 500
weight_sync_interval: 10  # Sync weights to external agent if supported
